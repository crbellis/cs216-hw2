# -*- coding: utf-8 -*-
"""HW2 Chase Bellisime.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10-xD0LLq1RqR8RO6aIg2CycttzZ0wU0L
"""

import random
import numpy as np
import matplotlib.pyplot as plt
import cv2

import cv2
import numpy as np
import random
import os

IMG_DIM = 180
PROCESS_IMGS = 1000
TARGET_IMG_PATH = "./drive/MyDrive/homer_bart_1/bart4.bmp"

def random_color():
    r = random.randint(0, 255)
    g = random.randint(0, 255)
    b = random.randint(0, 255)
    return (r, g, b)

def random_image_background(width, height, channels):
    image = np.zeros((width, height, channels), dtype=np.uint8)
    color = random_color()
    image[:] = color
    return image

def add_image_on_top(background_image, top_image, x, y):
    w, h = background_image.shape[1] // 6, background_image.shape[0] // 6
    top_image = cv2.resize(top_image, (w, h))
    for i in range(top_image.shape[0]):
        for j in range(top_image.shape[1]):
            for k in range(top_image.shape[2]):
                if top_image[i, j, k] != 0:
                    background_image[y + i, x + j, k] = top_image[i, j, k]
    return background_image, (x, y, w, h), top_image

def random_image_with_top(
    width, 
    height, 
    channels, 
    top_image_path, 
    background_function=random_image_background
):
    top_image = cv2.imread(top_image_path)
    top_image = cv2.cvtColor(top_image, cv2.COLOR_BGR2RGB)
    if background_function == random_image_background:
      background_image = background_function(width, height, channels)
    else:
      background_image = background_function(width, height, 50)
    step = 30
    x = random.randint(0, (background_image.shape[1] // step) - 1) * step
    y = random.randint(0, (background_image.shape[0] // step) - 1) * step
    return add_image_on_top(background_image, top_image, x, y)

def split_into_categories(final_image, x, y, w, h):
    category_1 = []
    category_2 = []
    step = 30
    for i in range(0, final_image.shape[0], step):
        for j in range(0, final_image.shape[1], step):
            has_top_image = False
            for k in range(step):
                for l in range(step):
                    if (y <= i + k < y + h) and (x <= j + l < x + w):
                        has_top_image = True
                        break
                if has_top_image:
                    break
            if has_top_image:
                category_1.append(final_image[i:i + step, j:j + step, :])
            else:
                category_2.append(final_image[i:i + step, j:j + step, :])
    return category_1, category_2

def plot_images(images, n):
    fig, ax = plt.subplots(n, n, figsize=(8, 8))
    for i in range(n):
        for j in range(n):
            index = i * n + j
            ax[i, j].imshow(images[index])
            ax[i, j].axis('off')
    plt.subplots_adjust(wspace=0.1, hspace=0.1)
    plt.show()

def get_category_splits(background_function=random_image_background):
  final_images = []
  total_bart = []
  total_no_bart = []
  for i in range(PROCESS_IMGS):
      width, height, channels = IMG_DIM, IMG_DIM, 3
  
      # generate image
      final_image, location, top_image = random_image_with_top(
          width, 
          height, 
          channels, 
          TARGET_IMG_PATH, 
          background_function
      )
      final_images.append(final_image)
      bart, no_bart = split_into_categories(final_image, location[0], location[1], location[2], location[3])
      total_bart.append(bart)
      total_no_bart.append(no_bart)
  
  # convert to numpy
  total_bart = np.array(total_bart)  
  total_no_bart = np.array(total_no_bart)
  total_bart = total_bart.reshape(-1, 30, 30, 3) # flatten
  total_no_bart = total_no_bart.reshape(-1, 30, 30, 3) # flatten array into 
  return total_bart, total_no_bart, final_images


total_bart, total_no_bart, final_images = get_category_splits()
"""
reshape data to reflect patches of data. in this case our patches are 30x30 
RGB pixels
as a result of our image being 1/6 the size of the 180x180 original image, 
we have 35 times the amount of non-bart classes as we do bart classes"""

print(total_bart[0].shape) # a single patch with bart
print(total_bart.shape) # total train set shape for our positive class
print(total_no_bart.shape) # total train set shape for our negative class
print(total_no_bart[0].shape) # single patch size with no bart

def display_images(images, rows, columns, title):
    fig = plt.figure(figsize=(20, 10))
    fig.suptitle(title, fontsize=16)
    for i, image in enumerate(images):
        fig.add_subplot(rows, columns, i+1)
        plt.imshow(image)
        plt.axis("off")
    plt.show()
 
index = 9
noBartIndex = index*35


display_images(
    [total_bart[index]], 10, 10, "Class 1: 30x30 Pixel Patches with Bart"
)
display_images(
    total_no_bart[noBartIndex:(noBartIndex) + 35], 10, 10, "Class 0: 30x30 Pixel Patches with No Bart"
)

plt.title("Original synthetic image")
plt.imshow(final_images[index])
plt.axis("off")
plt.show()

from sklearn.model_selection import train_test_split
def merge_into_training_set(category_1, category_2):
    category_1_array = np.array(category_1)
    category_2_array = np.array(category_2)
    
    # Create labels for the two categories
    category_1_labels = np.ones(category_1_array.shape[0]) # 1 for bart
    category_2_labels = np.zeros(category_2_array.shape[0]) # 0 for no bart
    
    # Merge the two arrays into a single input set
    X = np.concatenate((category_1_array, category_2_array), axis=0)
    
    # Merge the two label arrays into a single label set
    y = np.concatenate((category_1_labels, category_2_labels), axis=0)
    return train_test_split(X, y, test_size=0.2)

x_train, x_test, y_train, y_test = merge_into_training_set(total_bart, total_no_bart)
assert x_train.shape[0] + x_test.shape[0] == len(total_no_bart) + len(total_bart) # make sure test and train dataset equal original data size
print("TRAINING SET SIZE: ", len(x_train))

"""# Models
## 1) Vector based linear model
"""

vector_size = (IMG_DIM//6)**2*3
def standardize(data):
  return data.astype(np.float32) / 255

from sklearn.linear_model import LogisticRegression
# load data

def runMeanLinear(total_bart=total_bart, total_no_bart=total_no_bart):
  """
  Simple linear classifer to determine if the current average is 
  greater than the difference then the class is positive 
  """
  temp_bart = standardize(total_bart)
  temp_no_bart = standardize(total_no_bart)
  temp_bart = temp_bart.reshape(-1, vector_size)
  temp_no_bart = temp_no_bart.reshape(-1, vector_size)

  # Compute the mean of the positive and negative classes
  mean_bart = np.mean(temp_bart, axis=0)
  mean_no_bart = np.mean(temp_no_bart, axis=0)
  # Compute the difference between the means
  weights = mean_bart - mean_no_bart
  return np.mean(weights)
  
mean = runMeanLinear()
print(mean)

plt.imshow(x_test[45]) # confirming test set
plt.show()

from sklearn.metrics import accuracy_score
def meanPredict(x_test, mean):
  x_test = standardize(x_test)
  x_test_temp = x_test.reshape(-1, vector_size)
  y_pred = []
  for x in x_test_temp:
    avg = np.mean(x, axis=0)
    if avg >= mean:
      y_pred.append(1)
    else:
      y_pred.append(0)
  print("ACCURACY: ", accuracy_score(y_test, y_pred))
meanPredict(x_test, mean)

"""## 2) Linear model on patches"""

from sklearn.linear_model import LogisticRegression
def fitLinear(x_train = None, y_train = None):
  if x_train is None and y_train is None:
    x_train, x_test, y_train, y_test = merge_into_training_set(total_bart, total_no_bart) # reset datasets
  
  # standardize the data to be between 0 and 1
  x_train = standardize(x_train) 
  # x_test = standardize(x_test) 
  
  x_train = x_train.reshape(-1, vector_size)
  print(x_train.shape)
  # x_test = x_test.reshape(-1, vector_size)
  clf = LogisticRegression(fit_intercept=False)
  clf.fit(x_train, y_train)
  return clf

clf = fitLinear()

x_test = standardize(x_test)
y_pred = clf.predict(x_test.reshape(-1, vector_size))
print("ACCURACY: ", accuracy_score(y_test, y_pred))

exampleInput = standardize(total_bart[0].reshape(1, -1)) # example of BART input
print(exampleInput.shape)
print("PREDICTION (LABEL: 1): ", clf.predict(exampleInput))

exampleEmptyInput = standardize(total_no_bart[0].reshape(1, -1)) # example of NO BART input
print(exampleEmptyInput.shape)
print("PREDICTION (LABEL: 0): ", clf.predict(exampleEmptyInput))

"""In this case, we see much better performance however, one caveat is that our dataset is very biased.

## 3) Neural net based model
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

vector_size = (IMG_DIM//6)**2*3

class SimpleNeuralNet(nn.Module):
    def __init__(self):
        super(SimpleNeuralNet, self).__init__()
        self.fc1 = nn.Linear(2700, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 1)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = torch.sigmoid(self.fc3(x))
        return x

def trainNN(x_train = None, y_train = None, epochs=1):
  if x_train is None and y_train is None:
    x_train, x_test, y_train, y_test = merge_into_training_set(total_bart, total_no_bart) # reset datasets

  x_train = x_train.astype(np.float32) / 255
  # x_test = x_test.astype(np.float32) /255
  
  x_train = x_train.reshape(-1, vector_size) # reshape training data to 1d array of size 30*30*3 or (batch_size, 2700)
  # x_test = x_test.reshape(-1, vector_size)
  print(x_train.shape) 
  X_train = torch.tensor(x_train, dtype=torch.float32)
  y_train = torch.tensor(y_train, dtype=torch.float32)

  # Initialize the network and loss function
  net = SimpleNeuralNet()
  criterion = nn.BCELoss()
  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

  # Train the network
  for epoch in range(epochs):  # loop over the dataset multiple times

      running_loss = 0.0
      for i, data in enumerate(X_train):
          inputs, labels = data, y_train[i].view(-1)

          # zero the parameter gradients
          optimizer.zero_grad()

          # forward + backward + optimize
          outputs = net(inputs)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()

          # print statistics
          running_loss += loss.item()
          if i % 5 == 0:    # print every 2000 mini-batches
              print('\r[%d, %5d] loss: %.3f' %
                    (epoch + 1, i + 1, running_loss / 2000), end="")
              running_loss = 0.0
  print()
  print('Finished Training')
  return net

net = trainNN()

"""## Neural Net results"""

def testNN(net):
  x_train, x_test, y_train, y_test = merge_into_training_set(total_bart, total_no_bart) # reset datasets
  x_test = standardize(x_test).reshape(-1, vector_size)
  x_test = torch.tensor(x_test, dtype=torch.float32)
  y_test = torch.tensor(y_test.reshape(-1, 1))
  with torch.no_grad():
      correct = 0
      total = 0
      outputs = net(torch.tensor(x_test, dtype=torch.float32))
      predicted = (outputs > 0.5).long()
      total += y_test.shape[0]
      correct += (predicted == y_test).sum()
  
  print('Accuracy of the network on the test images: %d %%' % (
      100 * correct / total))

testNN(net)

exampleInput = standardize(total_bart[0])
exampleInput = exampleInput.reshape(-1, vector_size)
net(torch.tensor(exampleInput, dtype=torch.float32)) # output probability is very confident this is bart

"""# Initial Conclusions
Both the linear classifiers and the neural net are very easily able to determine which pixel patches are Bart and which are not Bart. This intuitively makes sense given the synthesized data. In our case, Bart always has the same pixel values and the background never overlaps. One relationship our algorithm could be learning is that: if there is a value of 1 in the patch, predict Bart, for example.

So, naturally, let's make things more complicated.

# Going Beyond
One way to make this more complicated is by creating more noisy backgrounds. Currently we are only looking at Bart on top of clean, single color backgrounds.
Let's add random shapes and colors to make this detection more complicated.
"""

def create_random_shape_background(height, width, num_shapes=50, max_shape_size=50):
    # create a blank image with black background
    img = np.zeros((height, width, 3), dtype=np.uint8)

    # generate a random set of shapes and colors
    for i in range(num_shapes):
        x1 = np.random.randint(0, width)
        y1 = np.random.randint(0, height)
        x2 = np.clip(x1 + np.random.randint(-max_shape_size, max_shape_size), 0, width)
        y2 = np.clip(y1 + np.random.randint(-max_shape_size, max_shape_size), 0, height)
        color = tuple(map(int, np.random.randint(0, 256, size=(3,))))
        shape_type = np.random.choice(['circle', 'rectangle', 'triangle'])

        # draw the shape on the image
        if shape_type == 'circle':
            center = (int((x1 + x2) / 2), int((y1 + y2) / 2))
            radius = int(np.sqrt((x2 - x1)**2 + (y2 - y1)**2) / 2)
            cv2.circle(img, center, radius, color, -1)
        elif shape_type == 'rectangle':
            cv2.rectangle(img, (x1, y1), (x2, y2), color, -1)
        else:
            points = np.array([[x1, y2], [(x1 + x2) // 2, y1], [x2, y2]], np.int32)
            cv2.fillConvexPoly(img, points, color)

    return img

total_bart, total_no_bart, final_images = get_category_splits(background_function=create_random_shape_background)
plt.imshow(final_images[0])
plt.axis("off")
plt.show()

x_train, x_test, y_train, y_test = merge_into_training_set(total_bart, total_no_bart)
assert x_train.shape[0] + x_test.shape[0] == len(total_no_bart) + len(total_bart) # make sure test and train dataset equal original data size
print("TRAINING SET SIZE: ", len(x_train))

plt.imshow(total_bart[6])
plt.show()

mean = runMeanLinear(total_bart, total_no_bart)
meanPredict(x_test, mean)

clf = fitLinear(x_train, y_train)
x_test = standardize(x_test)
y_pred = clf.predict(x_test.reshape(-1, vector_size))
print("ACCURACY: ", accuracy_score(y_test, y_pred))

net = trainNN(x_train, y_train)
testNN(net)

